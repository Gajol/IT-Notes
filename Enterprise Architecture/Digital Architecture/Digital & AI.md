# Digital & AI

>  Technology is power.   

> If you want to understand power in the 21st century, you have to understand technology. 

> *"We need a referee… [This meeting] may go down in history as very important to the future of civilization.”* — Elon Musk ([MSN article  Tech Leaders meet Lawmakers](https://www.msn.com/en-in/news/world/elon-musk-calls-ai-a-double-edge-sword-says-we-need-to-regulate-it-to-ensure-safety/ar-AA1gGFQi))

# Problem

## The Containment Problem

- [Mustafa Suleyman](https://mustafa-suleyman.ai/) - Author of "The Coming Wave", [Inflection AI](https://inflection.ai/) - pi.ai

- > *We commit to never selling or sharing your data with any oter party, under any circumstances without your explicit, plain English permission.*

## The Alignment Problem

[AI Alignment - Wikipedia](https://en.wikipedia.org/wiki/AI_alignment): **AI alignment** research aims to steer AI systems towards humans' intended goals, preferences, or ethical principles. An AI system is considered *aligned* if it advances the intended objectives. A *misaligned* AI system pursues some objectives, but not the intended ones.

AI alignment is a subfield of [AI safety](https://en.wikipedia.org/wiki/AI_safety), the study of how to build safe AI systems.[[18\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-concrete2016-19) Other subfields of AI safety include robustness, monitoring, and [capability control](https://en.wikipedia.org/wiki/AI_capability_control).[[19\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-building2018-20) Research challenges in alignment include instilling complex values in AI, avoiding deceptive AI,[[20\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-deception2023-21) scalable oversight, auditing and interpreting AI models, and preventing emergent AI behaviors like power-seeking.[[19\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-building2018-20) Alignment research has connections to [interpretability research](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence),[[21\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-:333-22)[[22\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-23) (adversarial) robustness,[[18\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-concrete2016-19) [anomaly detection](https://en.wikipedia.org/wiki/Anomaly_detection), [calibrated uncertainty](https://en.wikipedia.org/wiki/Uncertainty_quantification),[[21\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-:333-22) [formal verification](https://en.wikipedia.org/wiki/Formal_verification),[[23\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-24) [preference learning](https://en.wikipedia.org/wiki/Preference_learning),[[24\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-prefsurvey2017-25)[[25\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-drlfhp-26)[[26\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-LessToxic-27) [safety-critical engineering](https://en.wikipedia.org/wiki/Safety-critical_system),[[27\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-28) [game theory](https://en.wikipedia.org/wiki/Game_theory),[[28\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-29) [algorithmic fairness](https://en.wikipedia.org/wiki/Fairness_(machine_learning)),[[18\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-concrete2016-19)[[29\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-30) and the [social sciences](https://en.wikipedia.org/wiki/Social_science),[[30\]](https://en.wikipedia.org/wiki/AI_alignment#cite_note-31) among others.

Resemblance to parenting:

> The story of human civilization has always been about how to instill values in strange, alien, human-level intelligences who will inevitably inherit the reins of society from us—namely, our kids. — Brian Christian *The Alignment Problem*

# AI Leaders

Sam Altman: CEO of OpenAI

Elon Musk

Mark Zuckerberg

Geoff Hinton

[Demis Hassabis](https://en.wikipedia.org/wiki/Demis_Hassabis): DeepMind co-founder

Yann LeCun

Fei-Fei Li

Jeff Dean

# References

Telling the Story of Generative AI and Humanity - Nina Schick: [Senators get schooled by Musk](https://ninaschick.substack.com/p/senators-get-schooled-by-musk-et?utm_medium=email&utm_source=multiple-personal-recommendations-email)

Books

"The Ethical Algorithm" by Michael Kearns: Ethical issues on AI; transparency, bias, privacy, safety

"Weapons of Math Destruction" by Cathy O'Neil: Societal impacts of AI

"Everybody Lies": Seth Stephens-Davidowitz: big data, technology used to understand human behaviour and psychology, the use of data and potential for bias and discrimination









